{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_senti3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9+CgMy3g0Lgt+H+HcO5KO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aku019/Analytics-ML-DL-Learning/blob/main/tweet_senti3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqjOr_V8ezr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "203a1bdc-2491-4e1f-fa76-5a1009a34a2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlbwKZBWj62s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6381b5c5-9e39-40ea-b3f1-e5368e7e743a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "test = pd.read_csv(\"/gdrive/My Drive/AV/tweet/test.csv\")\n",
        "train = pd.read_csv(\"/gdrive/My Drive/AV/tweet/train.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFobovzkMxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "608f0671-aa1a-48e0-ce26-da5273d2d65e"
      },
      "source": [
        "train.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31962 entries, 0 to 31961\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      31962 non-null  int64 \n",
            " 1   label   31962 non-null  int64 \n",
            " 2   tweet   31962 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 749.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABG_N4T6kQq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "578c745d-cb7f-4f71-cbb8-e0e3ee6467b7"
      },
      "source": [
        "train.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       0\n",
              "label    0\n",
              "tweet    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF9LI7ohkTZb"
      },
      "source": [
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(string):\n",
        "    word_list = [word.lower() for word in string.split()]\n",
        "    stopwords_list = list(stopwords.words(\"english\"))\n",
        "    for word in word_list:\n",
        "        if word in stopwords_list:\n",
        "            word_list.remove(word)\n",
        "    return ' '.join(word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lf5LCobkT_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "6cc69c1b-14cb-4234-c774-55933e854743"
      },
      "source": [
        "train['tweet_length'] = train['tweet'].apply(len)\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'\\W',' ',str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'https\\s+|www.\\s+',r'', str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'http\\s+|www.\\s+',r'', str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'\\s+[a-zA-Z]\\s+',' ',str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'\\^[a-zA-Z]\\s+',' ',str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'\\s+',' ',str(x)))\n",
        "train['tweet'] = train['tweet'].str.lower()\n",
        "\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\’\", \"\\'\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"won\\'t\", \"will not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"can\\'t\", \"can not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"don\\'t\", \"do not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"dont\", \"do not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"n\\’t\", \" not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"n\\'t\", \" not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'re\", \" are\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'s\", \" is\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\’d\", \" would\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\d\", \" would\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'ll\", \" will\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'t\", \" not\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'ve\", \" have\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'m\", \" am\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\n\", \"\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\r\", \"\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"[0-9]\", \"digit\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\'\", \"\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r\"\\\"\", \"\", str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'[?|!|\\'|\"|#]',r'', str(x)))\n",
        "train['tweet'] = train['tweet'].map(lambda x: re.sub(r'[.|,|)|(|\\|/]',r' ', str(x)))\n",
        "train['tweet'] = train['tweet'].apply(lambda x: remove_stopwords(x))\n",
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>user father dysfunctional is selfish drags kid...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>user user thanks lyft credit use cause don off...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday majesty</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>model love take all time urð ð ð ð ð ð ð ð</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide society motivation</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>would would huge fan fare big talking they lea...</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>user camping tomorrow user user user user user...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>next school year the year exams ð think that ð...</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>won love land allin cavs champions cleveland c...</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>user user welcome m so gr would</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet  tweet_length\n",
              "0   1      0  user father dysfunctional is selfish drags kid...           102\n",
              "1   2      0  user user thanks lyft credit use cause don off...           122\n",
              "2   3      0                                     bihday majesty            21\n",
              "3   4      0         model love take all time urð ð ð ð ð ð ð ð            86\n",
              "4   5      0                      factsguide society motivation            39\n",
              "5   6      0  would would huge fan fare big talking they lea...           116\n",
              "6   7      0  user camping tomorrow user user user user user...            74\n",
              "7   8      0  next school year the year exams ð think that ð...           143\n",
              "8   9      0  won love land allin cavs champions cleveland c...            87\n",
              "9  10      0                    user user welcome m so gr would            50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUoN2m2MktV9"
      },
      "source": [
        "test['tweet'] = test['tweet'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'\\W',' ',str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'\\s+[a-zA-Z]\\s+',' ',str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'\\^[a-zA-Z]\\s+',' ',str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'\\s+',' ',str(x)))\n",
        "test['tweet'] = test['tweet'].str.lower()\n",
        "\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\’\", \"\\'\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"won\\'t\", \"will not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"can\\'t\", \"can not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"don\\'t\", \"do not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"dont\", \"do not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"n\\’t\", \" not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"n\\'t\", \" not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'re\", \" are\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'s\", \" is\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\’d\", \" would\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\d\", \" would\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'ll\", \" will\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'t\", \" not\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'ve\", \" have\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'m\", \" am\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\n\", \"\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\r\", \"\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"[0-9]\", \"digit\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\'\", \"\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r\"\\\"\", \"\", str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'[?|!|\\'|\"|#]',r'', str(x)))\n",
        "test['tweet'] = test['tweet'].map(lambda x: re.sub(r'[.|,|)|(|\\|/]',r' ', str(x)))\n",
        "test['tweet'] = test['tweet'].apply(lambda x: remove_stopwords(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDZ5hZeCk0Ky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "4028ef5a-6e1f-41d0-f888-8799703fd223"
      },
      "source": [
        "test.tail(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17187</th>\n",
              "      <td>49150</td>\n",
              "      <td>loving lifeð ºð â ï ð createyourfuture lifesty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17188</th>\n",
              "      <td>49151</td>\n",
              "      <td>black professor demonizes proposes nazi style ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17189</th>\n",
              "      <td>49152</td>\n",
              "      <td>learn to think positive positive instagram ins...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17190</th>\n",
              "      <td>49153</td>\n",
              "      <td>love pretty happy fresh teenilicious fixdermat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17191</th>\n",
              "      <td>49154</td>\n",
              "      <td>would_damn_tuff ruff_muff__techno_city ng woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17192</th>\n",
              "      <td>49155</td>\n",
              "      <td>thought factory left right polarisation trump ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17193</th>\n",
              "      <td>49156</td>\n",
              "      <td>feeling like mermaid ð hairflip neverready for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17194</th>\n",
              "      <td>49157</td>\n",
              "      <td>hillary campaigned today ohio omg amp used wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17195</th>\n",
              "      <td>49158</td>\n",
              "      <td>happy work conference right mindset leads cult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17196</th>\n",
              "      <td>49159</td>\n",
              "      <td>song glad free download shoegaze newmusic newsong</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "17187  49150  loving lifeð ºð â ï ð createyourfuture lifesty...\n",
              "17188  49151  black professor demonizes proposes nazi style ...\n",
              "17189  49152  learn to think positive positive instagram ins...\n",
              "17190  49153  love pretty happy fresh teenilicious fixdermat...\n",
              "17191  49154  would_damn_tuff ruff_muff__techno_city ng woul...\n",
              "17192  49155  thought factory left right polarisation trump ...\n",
              "17193  49156  feeling like mermaid ð hairflip neverready for...\n",
              "17194  49157  hillary campaigned today ohio omg amp used wor...\n",
              "17195  49158  happy work conference right mindset leads cult...\n",
              "17196  49159  song glad free download shoegaze newmusic newsong"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnO1PBqtk4JY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "aee1cfb9-cf98-4419-f080-b38f69733a5a"
      },
      "source": [
        "\n",
        "train2 = train.drop('label', axis=1)\n",
        "target = train[\"label\"]\n",
        "target.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fXATQajlTzr"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(train2, target, test_size=0.3, random_state=2019)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nB4Y3jvlARv"
      },
      "source": [
        "\n",
        "import string\n",
        "\n",
        "def process_text(text):\n",
        "    '''\n",
        "    What will be covered:\n",
        "    1. Remove punctuation\n",
        "    2. Remove stopwords\n",
        "    3. Return list of clean text words\n",
        "    '''\n",
        "    \n",
        "    #1\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    \n",
        "    #2\n",
        "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
        "    \n",
        "    #3\n",
        "    return clean_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErqpvADhlHFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea11f2c5-5b65-4f36-df9b-223778906cd2"
      },
      "source": [
        "vec = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}', ngram_range=(1, 4), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = 'english')\n",
        "\n",
        "#vec = HashingVectorizer()\n",
        "\n",
        "#X_train_counts = vec.fit_transform(x_train['tweet'])\n",
        "X_train_counts = vec.fit_transform(train['tweet'])\n",
        "\n",
        "# TF-IDF\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31962, 23097)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0YLKZIdlHtX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5857c86-7d01-444a-b2a5-0cf9d6b57fbd"
      },
      "source": [
        "X_val_counts = vec.transform(x_val['tweet'])\n",
        "X_val_tfidf = tfidf_transformer.transform(X_val_counts)\n",
        "print(X_val_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9589, 23097)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmdbsXKRlKoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91ce5d43-803f-4b90-d730-a2816c41b913"
      },
      "source": [
        "X_test_counts = vec.transform(test['tweet'])\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "print(X_test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17197, 23097)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaOeOnbolckL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95792571-3ee2-41e6-df02-590b709a28b3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf_log = LogisticRegression(random_state=2019, C=1000).fit(X_train_tfidf, target)\n",
        "#clf_log = LogisticRegression(random_state=2019, C=100).fit(X_train_tfidf, y_train)\n",
        "#clf_log = LogisticRegression(random_state=2019, solver='lbfgs',C=10).fit(X_train_tfidf, y_train)\n",
        "y_pred = clf_log.predict(X_test_tfidf)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4lcTqXrljRH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5e1126f2-4d61-43bd-b924-59040433671b"
      },
      "source": [
        "for c in [10, 50, 100, 1000, 10000]:\n",
        "    lr = LogisticRegression(C=c, random_state=2019).fit(X_train_tfidf, target)\n",
        "    #lr = LogisticRegression(C=c, random_state=2019).fit(X_train_tfidf, y_train)\n",
        "    print (\"f1 score for C=%s: %s\" % (c, f1_score(y_val, lr.predict(X_val_tfidf))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score for C=10: 0.926865671641791\n",
            "f1 score for C=50: 0.9957805907172996\n",
            "f1 score for C=100: 0.9978917779339423\n",
            "f1 score for C=1000: 0.9985955056179775\n",
            "f1 score for C=10000: 0.9985955056179775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMdw9SNolp7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bc327c2-d6af-4ece-93ff-edf25db9560e"
      },
      "source": [
        "#print(f1_score(y_val, clf_log.predict(X_val_tfidf), average='micro'))\n",
        "print(f1_score(y_val, clf_log.predict(X_val_tfidf), average='macro'))\n",
        "#print(f1_score(y_val, clf_log.predict(X_val_tfidf), average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.999241427473853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKuwGiolqxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b7a458ec-8265-4547-d964-dd8610aaef66"
      },
      "source": [
        "submission = {}\n",
        "submission['id'] = test['id']\n",
        "submission['label'] = y_pred\n",
        "submission = pd.DataFrame(submission)\n",
        "submission = submission[['id', 'label']]\n",
        "submission.to_csv(\"submisision.csv\", index=False)\n",
        "print(submission['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    16089\n",
            "1     1108\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scJp2awamGhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c6ad40e3-4400-4df0-cf4d-6ec05617bfb4"
      },
      "source": [
        "!ls -ltr\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 140\n",
            "drwxr-xr-x 1 root root   4096 May  4 16:26 sample_data\n",
            "-rw-r--r-- 1 root root 137585 May  6 15:26 submisision.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkBIoOgVltoM"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submisision.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ST_y2l_mcUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "406c7e39-fc15-47fa-a000-2d2499381644"
      },
      "source": [
        "\n",
        "#XG Boost Classifier\n",
        "from xgboost import XGBClassifier\n",
        "clf_xgb = XGBClassifier(random_state=2019, params = {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators':200, 'subsample':0.6, 'objective':'binary:logistic'}).fit(X_train_tfidf, target)\n",
        "y_pred = clf_xgb.predict(X_test_tfidf)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mQ0NDsRmj0K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "162046f8-66a3-4e93-ffed-8aa90d9b4a72"
      },
      "source": [
        "clf_xgb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic',\n",
              "              params={'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200,\n",
              "                      'objective': 'binary:logistic', 'subsample': 0.6},\n",
              "              random_state=2019, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hze2BQrgnMZs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOH77_rFmqh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fbe80a6-cb47-4502-bef0-d1776eb0ed25"
      },
      "source": [
        "lr = clf_xgb.fit(X_train_tfidf, target)\n",
        "    #lr = LogisticRegression(C=c, random_state=2019).fit(X_train_tfidf, y_train)\n",
        "print ( f1_score(y_val, lr.predict(X_val_tfidf)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3611738148984199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83JHq4CrnEMW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d78685c0-14d9-46ca-9d4a-d5d9df3529fa"
      },
      "source": [
        "#Ada Boost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf_abc = AdaBoostClassifier(random_state=2019).fit(X_train_tfidf, target)\n",
        "y_pred = clf_abc.predict(X_test_tfidf)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWmn37HqnUlJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff446133-d070-42fb-84c8-7a4fbcca97f1"
      },
      "source": [
        "lr = clf_abc.fit(X_train_tfidf, target)\n",
        "    #lr = LogisticRegression(C=c, random_state=2019).fit(X_train_tfidf, y_train)\n",
        "print ( f1_score(y_val, lr.predict(X_val_tfidf)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4895238095238095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBOQ8eOncmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "860a832f-eade-4908-b881-93b643a0d836"
      },
      "source": [
        "\n",
        "#Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "# #clf_gbc = GradientBoostingClassifier(random_state=2019).fit(X_train_tfidf, target)\n",
        "clf_gbc = GradientBoostingClassifier(n_estimators=300,max_depth=5,random_state=2019).fit(X_train_tfidf, target)\n",
        "y_pred = clf_gbc.predict(X_test_tfidf)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFoBgnSfn44Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da888bfa-e28d-489c-ae81-d022be902aff"
      },
      "source": [
        "lr = clf_gbc.fit(X_train_tfidf, target)\n",
        "    #lr = LogisticRegression(C=c, random_state=2019).fit(X_train_tfidf, y_train)\n",
        "print ( f1_score(y_val, lr.predict(X_val_tfidf)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7141585040071239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aQVIYUZn7Am"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}